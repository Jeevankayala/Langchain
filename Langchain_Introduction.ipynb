{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65105533",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_api_key = \"use your own gemini api key which you can get from https://aistudio.google.com/apikey\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "148f60dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "llm = GoogleGenerativeAI(temperature = 0.5, model = \"gemini-pro\", api_key = gemini_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3a10de8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"* **Aahar Amrit** (Divine Nectar of Food)\\n* **Amrita Mahal** (Palace of Ambrosia)\\n* **Bhojan Bhavna** (Ode to Cuisine)\\n* **Chakra** (Symbol of Harmony and Balance)\\n* **Daawat-e-Nawab** (Feast of the Noble)\\n* **Deva Bhoga** (Food Fit for Gods)\\n* **Indra's Table** (Table of the King of Heaven)\\n* **Maharaja's Feast** (Feast of the Emperor)\\n* **Nirvana** (State of Bliss and Transcendence)\\n* **Rasoi Royale** (Royal Kitchen)\\n* **Saffron & Silk** (Exotic Spices and Luxurious Fabrics)\\n* **Spice Odyssey** (Culinary Journey of Flavors)\\n* **Tandoori Temptation** (Alluring Clay Oven Delights)\\n* **The Golden Thali** (Plate of Abundance and Prosperity)\\n* **Vasundhara** (Earth's Bounty)\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"I want to open a restaurant for Indian food. Please suggest me a fency name for this\"\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f51c30d",
   "metadata": {},
   "source": [
    "# Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "477725f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07eb910a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate(input_variables = ['cuisine'], template = \"I want to open a restaurant for {cuisine} food. Please suggest me one best fency name for this\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "637da631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want to open a restaurant for Italian food. Please suggest me one best fency name for this'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.format(cuisine = \"Italian\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a75e26",
   "metadata": {},
   "source": [
    "# LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c03fb55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\satya\\AppData\\Local\\Temp/ipykernel_18348/2626534554.py:2: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  my_chain = LLMChain(llm = llm, prompt = prompt_template)\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "my_chain = LLMChain(llm = llm, prompt = prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7716e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\satya\\AppData\\Local\\Temp/ipykernel_18348/801944951.py:1: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  my_chain.run(\"Mexican\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'**\"El Palacio de la Comida Mexicana\"**'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_chain.run(\"Mexican\")\n",
    "# my_chain.invoke(\"Indian\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c025e84",
   "metadata": {},
   "source": [
    "### use prompt | llm if LLMChain is Deprecated and chain.invoke instead of chain.run since they will be deprecated in upcoming langchain versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c49279e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**\"El Palacio de la Comida Mexicana\"**\n"
     ]
    }
   ],
   "source": [
    "chain = prompt_template | llm\n",
    "response = chain.invoke(input = \"Mexican\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b68403e",
   "metadata": {},
   "source": [
    "### SimpleSequentialChain example where the response of first llm call will be fed into second llm call automatically and there will be only 1 response that is final llm call's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f4c5477",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = GoogleGenerativeAI(temperature = 0.5, model = \"gemini-pro\", api_key = gemini_api_key)\n",
    "prompt_template1 = PromptTemplate(\n",
    "                input_variables = ['cuisine'], \n",
    "                template = \"I want to open a restaurant for {cuisine} food. Please suggest me one best fency name for this\" )\n",
    "chain1 = prompt_template1 | llm\n",
    "\n",
    "prompt_template2 = PromptTemplate(\n",
    "                input_variables = ['restaurant_name'], \n",
    "                template = \"Suggest me some menu items for {restaurant_name}. Return them as comma separated values\" )\n",
    "chain2 = prompt_template2 | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f871295c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Peking Duck, Mongolian Beef, Kung Pao Chicken, Szechuan Shrimp, Lo Mein, Wonton Soup, Egg Foo Young, Spring Rolls, Fried Rice, Fortune Cookies'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss_chain = chain | chain2\n",
    "ss_chain.invoke(\"Chinese\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a69d9f",
   "metadata": {},
   "source": [
    "### Sequentialchain where we can get the intermediate responses as well like restaurant name in below example by adding \"*output_key*\" in the chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11bd0175",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = GoogleGenerativeAI(temperature = 0.5, model = \"gemini-pro\", api_key = gemini_api_key)\n",
    "prompt_template1 = PromptTemplate(\n",
    "                input_variables = ['cuisine'], \n",
    "                template = \"I want to open a restaurant for {cuisine} food. Please suggest me one best fency name for this\" )\n",
    "chain1 = LLMChain(llm = llm, prompt = prompt_template1, output_key = \"restaurant_name\")\n",
    "# chain1 = prompt_template | llm\n",
    "\n",
    "prompt_template2 = PromptTemplate(\n",
    "                input_variables = ['restaurant_name'], \n",
    "                template = \"Suggest me some menu items for {restaurant_name}. Return them as comma separated values\" )\n",
    "chain2 = LLMChain(llm = llm, prompt = prompt_template2, output_key = \"menu_items\")\n",
    "# chain2 = prompt_template2 | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f1ced5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'restaurant_name': '**\"Rasa Royale\"**',\n",
       " 'menu_items': '**Appetizers:**\\n- Paneer Tikka, Chicken Tikka, Vegetable Samosas, Onion Bhajis\\n\\n**Main Course:**\\n- Butter Chicken, Chicken Tikka Masala, Saag Paneer, Dal Makhani\\n\\n**Sides:**\\n- Naan, Roti, Paratha, Raita\\n\\n**Desserts:**\\n- Gulab Jamun, Ras Malai, Kheer, Kulfi'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_chain = chain | chain2\n",
    "s_chain.invoke(\"Indian\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
